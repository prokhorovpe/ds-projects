"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ –Ω–æ–≤—ã–µ –¥–∞—Ç—ã. 
–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –±—É–¥–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å—Å—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤.
–ö–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ –æ—Ç model_trainer.py: –∑–¥–µ—Å—å –ù–ï–¢ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –∫–≤–∞–Ω—Ç–∏–ª–µ–π –∏ –º–∞–∫—Å–∏–º—É–º–æ–≤.
–í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (quantiles, max_vals) –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.
–≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏.
"""
import pandas as pd
import numpy as np
import pickle
import os
from config import MODEL_DIR, HIGH_FREQUENCY_MODALITIES, SPECIALIZED_MODALITIES, RU_HOLIDAYS, PAY_WINDOW_START, PAY_WINDOW_END, PAY_WINDOW_MID_START, PAY_WINDOW_MID_END, FORECAST_START_DATE, FORECAST_PERIOD_DAYS
from model_trainer import add_calendar_features, final_postprocessing  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏.

def load_model(filename):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å (–∏–ª–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç) –∏–∑ —Ñ–∞–π–ª–∞."""
    filepath = os.path.join(MODEL_DIR, filename)
    with open(filepath, 'rb') as f:
        model = pickle.load(f)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {filepath}")
    return model

def generate_future_dates(start_date, periods=60):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç DataFrame —Å –±—É–¥—É—â–∏–º–∏ –¥–∞—Ç–∞–º–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞."""
    dates = pd.date_range(start=start_date, periods=periods, freq='D')
    return pd.DataFrame({'ds': dates})

def predict_with_hybrid_model(modality, future_df):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ —Å –ø–æ–º–æ—â—å—é –≥–∏–±—Ä–∏–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ (Prophet + XGBoost).
    –î–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    """
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π.
    prophet_model = load_model(f"{modality}_prophet.pkl")
    xgb_model = load_model(f"{modality}_xgboost.pkl")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Prophet: –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.
    future_df_with_feats = add_calendar_features(future_df)
    prophet_regressors = [
        'is_holiday', 'is_weekend', 'is_extended_holiday',
        'near_holiday', 'sin_dow', 'is_pay_window', 'sin_month'
    ]
    future_for_prophet = future_df_with_feats[['ds'] + [r for r in prophet_regressors if r in future_df_with_feats.columns]]

    # –ü—Ä–æ–≥–Ω–æ–∑ Prophet.
    forecast = prophet_model.predict(future_for_prophet)
    forecast['yhat'] = np.clip(forecast['yhat'], 0, None)

    # –ê–î–ê–ü–¢–ò–í–ù–ê–Ø –û–ë–†–ï–ó–ö–ê –ò–ù–¢–ï–†–í–ê–õ–û–í
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤.
    from data_preprocessor import load_processed_data
    service_time_series = load_processed_data()
    train_df_raw = service_time_series[modality].reset_index()
    train_df_raw.columns = ['ds', 'y']
    train_df_raw['ds'] = pd.to_datetime(train_df_raw['ds'])
    train_df_raw['y'] = pd.to_numeric(train_df_raw['y'], errors='coerce').clip(lower=0)
    train_df_raw = train_df_raw.dropna(subset=['y']).reset_index(drop=True)
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.
    train_df = add_calendar_features(train_df_raw.copy())

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ –º–∞–∫—Å–∏–º—É–º—ã –¥–ª—è —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö/–ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤.
    is_holiday_weekend_mask = (train_df['is_holiday'] == 1) | (train_df['is_weekend'] == 1)
    max_possible_weekday = train_df[~is_holiday_weekend_mask]['y'].quantile(0.999)
    max_possible_weekend = train_df[is_holiday_weekend_mask]['y'].quantile(0.999) if is_holiday_weekend_mask.sum() > 0 else max_possible_weekday

    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫ forecast –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –¥–Ω—è.
    forecast_with_feats = add_calendar_features(forecast[['ds']].copy())
    is_forecast_weekend = (forecast_with_feats['is_holiday'] == 1) | (forecast_with_feats['is_weekend'] == 1)
    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è.
    max_vals = np.where(is_forecast_weekend, max_possible_weekend, max_possible_weekday)

    # –ü–û–õ–ù–û–°–¢–¨–Æ –°–ò–ú–ú–ï–¢–†–ò–ß–ù–´–ô –ò –ù–ï–û–ì–†–ê–ù–ò–ß–ï–ù–ù–´–ô –ò–ù–¢–ï–†–í–ê–õ
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    lower_width = forecast['yhat'].values - forecast['yhat_lower'].values
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Ä—Ö–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É –∫–∞–∫ –∑–µ—Ä–∫–∞–ª—å–Ω–æ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—É—é –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ yhat
    forecast['yhat_upper'] = forecast['yhat'].values + lower_width
    # –û–±—Ä–µ–∑–∞–µ–º –¢–û–õ–¨–ö–û –Ω–∏–∂–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É –¥–æ –Ω—É–ª—è (–≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–π)
    forecast['yhat_lower'] = np.clip(forecast['yhat_lower'], 0, None)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ—á–µ—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ Prophet.
    prophet_predictions = forecast.set_index('ds')['yhat']

    # –ü—Ä–æ–≥–Ω–æ–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é XGBoost.
    xgb_features = [col for col in future_df_with_feats.columns if col not in ['ds', 'y']]
    X_future = future_df_with_feats.set_index('ds')[xgb_features].fillna(0)
    resid_forecast = xgb_model.predict(X_future)

    # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑.
    final_forecast = prophet_predictions.values + resid_forecast

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º train_df (—Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏) –¥–ª—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏.
    final_forecast = final_postprocessing(final_forecast, prophet_predictions.values, future_df['ds'].values, modality, train_df)
    final_forecast = np.clip(final_forecast, 0, None)

    # –ò–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –æ—Ç Prophet (—É–∂–µ –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π!).
    yhat_lower = forecast.set_index('ds')['yhat_lower']
    yhat_upper = forecast.set_index('ds')['yhat_upper']

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π DataFrame.
    result_df = future_df.copy()
    result_df['y_pred'] = final_forecast  # <-- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
    result_df['yhat_lower'] = yhat_lower.values  # <-- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
    result_df['yhat_upper'] = yhat_upper.values  # <-- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ

    return result_df

def predict_with_spike_model(modality, future_df):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≤—Å–ø–ª–µ—Å–∫–æ–≤.
    –ö–ª—é—á–µ–≤–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: –∑–∞–≥—Ä—É–∂–∞–µ—Ç –í–°–ï –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã (–≤–∫–ª—é—á–∞—è quantiles –∏ max_vals) –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
    –≠—Ç–æ –∏—Å–∫–ª—é—á–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏.
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –µ–¥–∏–Ω—ã–π –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –º–æ–¥–µ–ª–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –í–°–ï –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã.
    spike_model_artifacts = load_model(f"{modality}_spike_model.pkl")
    classifier_model = spike_model_artifacts['classifier']
    regressor_normal = spike_model_artifacts['regressor_normal']
    regressor_spike = regressor_normal  # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è (regressor_spike —á–∞—Å—Ç–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ).
    quantiles = spike_model_artifacts['quantiles']  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –∫–≤–∞–Ω—Ç–∏–ª–∏ –æ—à–∏–±–æ–∫.
    max_vals = spike_model_artifacts['max_vals']    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –º–∞–∫—Å–∏–º—É–º—ã.
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–æ–¥–µ–ª–∏ –¥–ª—è {modality}: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä, –∫–≤–∞–Ω—Ç–∏–ª–∏, –º–∞–∫—Å–∏–º—É–º—ã.")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –±—É–¥—É—â–∏—Ö –¥–∞—Ç.
    future_df_with_feats = add_calendar_features(future_df)
    feature_cols = [col for col in future_df_with_feats.columns if col not in ['ds', 'y', 'is_spike', 'month', 'dow', 'group_key']]
    X_future = future_df_with_feats[feature_cols]

    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: –±—É–¥–µ—Ç –ª–∏ –≤—Å–ø–ª–µ—Å–∫ –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å?
    spike_predictions = classifier_model.predict(X_future)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—á–µ—á–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞.
    final_predictions = []
    for i, is_spike in enumerate(spike_predictions):
        if is_spike:
            pred = regressor_spike.predict(X_future.iloc[[i]])[0]
        else:
            pred = regressor_normal.predict(X_future.iloc[[i]])[0]
        final_predictions.append(max(0, pred))
    final_predictions = np.array(final_predictions)

    # –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–ù–¢–ï–†–í–ê–õ–û–í –î–õ–Ø –ë–£–î–£–©–ï–ì–û (–ò–°–ü–û–õ–¨–ó–£–ï–ú –ó–ê–ì–†–£–ñ–ï–ù–ù–´–ï quantiles –∏ max_vals)
    yhat_lower_list = []
    yhat_upper_list = []
    for i, is_spike in enumerate(spike_predictions):
        pred = final_predictions[i]
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–Ω—è –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ (—Ä–∞–±–æ—á–∏–π –∏–ª–∏ –≤—ã—Ö–æ–¥–Ω–æ–π/–ø—Ä–∞–∑–¥–Ω–∏–∫).
        is_workday = future_df_with_feats.iloc[i]['is_workday']
        if is_workday:
            q_lower = quantiles['workday']['lower']
            q_upper = quantiles['workday']['upper']
            max_val = max_vals['workday']
        else:
            q_lower = quantiles['weekend_or_holiday']['lower']
            q_upper = quantiles['weekend_or_holiday']['upper']
            max_val = max_vals['weekend_or_holiday']

        # –í–ê–ñ–ù–û: –í–´–ß–ò–°–õ–Ø–ï–ú –ì–†–ê–ù–ò–¶–´ –ò –î–û–ë–ê–í–õ–Ø–ï–ú –ò–• –í –°–ü–ò–°–ö–ò
        lower_bound = max(0, pred + q_lower)
        upper_bound = pred + q_upper
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –º–∞–∫—Å–∏–º—É–º–∞.
        lower_bound = min(lower_bound, max_val)
        upper_bound = min(upper_bound, max_val)
        yhat_lower_list.append(lower_bound)
        yhat_upper_list.append(upper_bound)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π DataFrame.
    result_df = future_df.copy()
    result_df['y_pred'] = final_predictions
    result_df['yhat_lower'] = yhat_lower_list
    result_df['yhat_upper'] = yhat_upper_list

    return result_df

def generate_forecasts_for_all_modalities(start_date="2025-09-01", periods=60):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.
    –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π Excel-—Ñ–∞–π–ª, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ –ª–∏—Å—Ç—ã —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º "–ë—É–¥—É—â–µ–µ_".
    """
    from config import RESULTS_DIR, FORECAST_START_DATE, FORECAST_PERIOD_DAYS
    future_df = generate_future_dates(FORECAST_START_DATE, FORECAST_PERIOD_DAYS)
    forecasts = {}

    for modality in HIGH_FREQUENCY_MODALITIES + SPECIALIZED_MODALITIES:
        print(f"\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è {modality}...")
        try:
            if modality in HIGH_FREQUENCY_MODALITIES:
                forecast_df = predict_with_hybrid_model(modality, future_df)
            elif modality in SPECIALIZED_MODALITIES:
                forecast_df = predict_with_spike_model(modality, future_df)
            else:
                print(f"–ü—Ä–æ–ø—É—Å–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏: {modality}")
                continue
            forecasts[modality] = forecast_df
            print(f"‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {modality} —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω. –†–∞–∑–º–µ—Ä: {forecast_df.shape}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è {modality}: {str(e)}")
            import traceback
            traceback.print_exc()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ –±—É–¥—É—â–µ–µ –≤ Excel
    output_excel_path = os.path.join(RESULTS_DIR, "forecasting_results.xlsx")
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å) –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π.
    mode = 'a' if os.path.exists(output_excel_path) else 'w'
    if mode == 'a':
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ª–∏—Å—Ç–æ–≤.
        with pd.ExcelFile(output_excel_path) as xls:
            existing_sheets = xls.sheet_names
    else:
        existing_sheets = []

    with pd.ExcelWriter(output_excel_path, engine='openpyxl', mode=mode, if_sheet_exists='replace') as writer:
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª, –∫–æ–ø–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –ª–∏—Å—Ç—ã (—Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã).
        if mode == 'a':
            with pd.ExcelFile(output_excel_path) as xls:
                for sheet_name in existing_sheets:
                    if not sheet_name.startswith('–ë—É–¥—É—â–µ–µ_'):
                        df = pd.read_excel(xls, sheet_name=sheet_name)
                        df.to_excel(writer, sheet_name=sheet_name, index=False)
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –±—É–¥—É—â–µ–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ª–∏—Å—Ç—ã.
        for modality, forecast_df in forecasts.items():
            if forecast_df is not None:
                sheet_name = f"–ë—É–¥—É—â–µ–µ_{modality}"[:31]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Excel.
                forecast_df.to_excel(writer, sheet_name=sheet_name, index=False)

    print(f"\n‚úÖ‚úÖ‚úÖ –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –±—É–¥—É—â–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {output_excel_path} ‚úÖ‚úÖ‚úÖ")

    return forecasts

if __name__ == "__main__":
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 123 –¥–Ω—è –≤–ø–µ—Ä–µ–¥ (–∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ config.py).
    all_forecasts = generate_forecasts_for_all_modalities()
    print("\nüéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")